"""
ReAct Engine - Reasoning and Acting Loop
Core reasoning engine implementing the ReAct framework
"""
import asyncio
import json
import logging
import re
import time
from typing import Any, AsyncGenerator, Dict, List, Optional
from datetime import datetime

from ..config import settings
from ..schemas.agent import AgentEvent, AgentEventType, StepResult, ToolAction
from .prompt_templates import (
    AGENT_SYSTEM_PROMPT,
    REACT_STEP_PROMPT,
    FINAL_ANSWER_TEMPLATE,
    ERROR_RECOVERY_PROMPT,
    format_history,
    format_observations,
    format_tool_list
)
from .skill_executor import skill_executor

logger = logging.getLogger(__name__)


class ReActEngine:
    """
    ReAct æ¨ç†å¼•æ“
    
    å®ç° Reasoning â†’ Action â†’ Observation å¾ªç¯
    """
    
    def __init__(
        self,
        llm_service=None,
        max_iterations: int = None,
        temperature: float = None
    ):
        """
        åˆå§‹åŒ– ReAct å¼•æ“
        
        Args:
            llm_service: LLM æœåŠ¡å®ä¾‹
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            temperature: LLM æ¸©åº¦å‚æ•°
        """
        self._llm_service = llm_service
        self.max_iterations = max_iterations or settings.AGENT_MAX_ITERATIONS
        self.temperature = temperature or settings.AGENT_DEFAULT_TEMPERATURE
        self.skill_executor = skill_executor
    
    @property
    def llm_service(self):
        """æ‡’åŠ è½½ LLM æœåŠ¡"""
        if self._llm_service is None:
            from ..services.llm_service import agent_llm_service
            self._llm_service = agent_llm_service
        return self._llm_service
    
    def _inject_context_params(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸ºç‰¹å®šå·¥å…·è‡ªåŠ¨æ³¨å…¥ä¸Šä¸‹æ–‡å‚æ•°
        
        ç›®å‰æ”¯æŒï¼š
        - memory_service: è‡ªåŠ¨æ³¨å…¥ session_idï¼ˆé™åˆ¶åœ¨å½“å‰ä¼šè¯å†…æœç´¢ï¼‰
        """
        if tool_name == "memory_service":
            # è‡ªåŠ¨æ³¨å…¥ session_id
            if "session_id" not in arguments and hasattr(self, '_current_context'):
                session_id = self._current_context.get("session_id")
                if session_id:
                    arguments = {**arguments, "session_id": session_id}
                    logger.debug(f"Auto-injected session_id for memory_service: {session_id}")
        
        return arguments
    
    async def run(
        self,
        task: str,
        context: Optional[Dict[str, Any]] = None,
        enabled_tools: Optional[List[str]] = None,
        disabled_tools: Optional[List[str]] = None
    ) -> AsyncGenerator[AgentEvent, None]:
        """
        æ‰§è¡Œ ReAct å¾ªç¯
        
        Args:
            task: ç”¨æˆ·ä»»åŠ¡/é—®é¢˜
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆçŸ¥è¯†ç©ºé—´ã€å†å²ç­‰ï¼‰
            enabled_tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨
            disabled_tools: ç¦ç”¨çš„å·¥å…·åˆ—è¡¨
            
        Yields:
            AgentEvent äº‹ä»¶æµ
        """
        start_time = time.time()
        history: List[Dict[str, Any]] = []
        observations: List[Dict[str, Any]] = []
        
        # ä¿å­˜å½“å‰ä¸Šä¸‹æ–‡ï¼Œä¾›å·¥å…·æ‰§è¡Œæ—¶ä½¿ç”¨
        self._current_context = context or {}
        
        # å‘é€å¼€å§‹äº‹ä»¶
        yield AgentEvent(
            type=AgentEventType.START,
            data={"task": task, "max_iterations": self.max_iterations}
        )
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        available_tools = self._get_available_tools(enabled_tools, disabled_tools)
        system_prompt = self._build_system_prompt(available_tools, context)
        
        for iteration in range(1, self.max_iterations + 1):
            logger.info(f"ReAct iteration {iteration}/{self.max_iterations}")
            
            # å‘é€è¿­ä»£å¼€å§‹äº‹ä»¶
            yield AgentEvent(
                type=AgentEventType.ITERATION,
                data={"iteration": iteration},
                iteration=iteration
            )
            
            try:
                # 1. æ€è€ƒé˜¶æ®µï¼šè°ƒç”¨ LLM è¿›è¡Œæ¨ç†
                step_result = await self._think(task, history, system_prompt)
                
                # å‘é€æ€è€ƒäº‹ä»¶
                yield AgentEvent(
                    type=AgentEventType.THOUGHT,
                    data=step_result.get("thought", ""),
                    iteration=iteration
                )
                
                # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆ
                if "final_answer" in step_result:
                    yield AgentEvent(
                        type=AgentEventType.FINAL_ANSWER,
                        data=step_result["final_answer"],
                        iteration=iteration,
                        execution_time=time.time() - start_time
                    )
                    
                    # å‘é€å®Œæˆäº‹ä»¶
                    yield AgentEvent(
                        type=AgentEventType.COMPLETE,
                        data={
                            "iterations": iteration,
                            "total_time": time.time() - start_time,
                            "tools_used": [obs["tool"] for obs in observations]
                        }
                    )
                    return
                
                # 3. è¡ŒåŠ¨é˜¶æ®µï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒå•ä¸ªæˆ–å¹¶è¡Œï¼‰
                actions_to_execute = []
                
                # æ”¯æŒå•ä¸ª action
                if step_result.get("action"):
                    actions_to_execute = [step_result["action"]]
                # æ”¯æŒå¹¶è¡Œ actions æ•°ç»„
                elif step_result.get("actions"):
                    actions_to_execute = step_result["actions"]
                
                # è¿‡æ»¤æ— æ•ˆçš„åŠ¨ä½œ
                actions_to_execute = [a for a in actions_to_execute if isinstance(a, dict)]
                
                if actions_to_execute:
                    # Check for duplicate actions to prevent infinite loops
                    unique_actions = []
                    duplicate_observations = []
                    
                    for action in actions_to_execute:
                        if self._is_duplicate_action(action, history):
                            logger.warning(f"Duplicate action detected: {action}")
                            # Create a fake observation for the duplicate action
                            dup_obs = {
                                "success": False,
                                "error": "SYSTEM WARNING: You have already executed this exact action in this session. Please modify your query or strategy significantly.",
                                "result": None
                            }
                            # Dispatch observation event immediately
                            yield AgentEvent(
                                type=AgentEventType.OBSERVATION,
                                data=dup_obs,
                                iteration=iteration,
                                tool_name=action.get("tool"),
                                execution_time=0
                            )
                            
                            # Add to tracking
                            duplicate_observations.append({
                                "tool": action.get("tool"),
                                "action": action,
                                "result": dup_obs
                            })
                            
                            # Add to global observations list if needed for final answer
                            observations.append({
                                "tool": action.get("tool"),
                                "result": dup_obs["error"]
                            })
                        else:
                            unique_actions.append(action)
                    
                    # Update actions to execute only unique ones
                    actions_to_execute = unique_actions
                    
                    # If we filtered out actions, we need to update history with the duplicate observations
                    if duplicate_observations:
                        if not actions_to_execute:
                            # All actions were duplicates, append history and continue to next iteration
                            history.append({
                                "thought": step_result.get("thought"),
                                "actions": [], # No real actions executed
                                "observations": [item["result"] for item in duplicate_observations] # But we have observations
                            })
                            continue
                        else:
                            # Mixed case: some duplicates, some unique. 
                            # We'll attach duplicate observations to the history entry created after unique execution
                            pass 

                if actions_to_execute:

                    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·
                    if len(actions_to_execute) > 1:
                        logger.info(f"Executing {len(actions_to_execute)} actions in parallel")
                        
                        # å‘é€å¹¶è¡Œè¡ŒåŠ¨å¼€å§‹äº‹ä»¶
                        for action in actions_to_execute:
                            yield AgentEvent(
                                type=AgentEventType.ACTION,
                                data={
                                    "tool": action.get("tool"),
                                    "method": action.get("method", "execute"),
                                    "arguments": action.get("arguments", {}),
                                    "parallel": True
                                },
                                iteration=iteration,
                                tool_name=action.get("tool")
                            )
                        
                        # å¹¶è¡Œæ‰§è¡Œ
                        async def execute_action(act):
                            try:
                                # è‡ªåŠ¨æ³¨å…¥ä¸Šä¸‹æ–‡å‚æ•°ï¼ˆå¦‚ memory_service çš„ session_idï¼‰
                                tool_name = act.get("tool")
                                arguments = self._inject_context_params(tool_name, act.get("arguments", {}))
                                
                                return await asyncio.wait_for(
                                    self.skill_executor.execute(
                                        skill_name=tool_name,
                                        method=act.get("method", "execute"),
                                        arguments=arguments
                                    ),
                                    timeout=settings.AGENT_TOOL_TIMEOUT
                                )
                            except asyncio.TimeoutError:
                                return {
                                    "success": False,
                                    "error": f"å·¥å…· {act.get('tool')} æ‰§è¡Œè¶…æ—¶",
                                    "result": None,
                                    "execution_time": settings.AGENT_TOOL_TIMEOUT
                                }
                        
                        execution_results = await asyncio.gather(
                            *[execute_action(act) for act in actions_to_execute],
                            return_exceptions=True
                        )
                        
                        # å‘é€æ‰€æœ‰è§‚å¯Ÿäº‹ä»¶
                        combined_observations = []
                        for i, (action, result) in enumerate(zip(actions_to_execute, execution_results)):
                            if isinstance(result, Exception):
                                result = {"success": False, "error": str(result), "result": None}
                            
                            yield AgentEvent(
                                type=AgentEventType.OBSERVATION,
                                data=result,
                                iteration=iteration,
                                tool_name=action.get("tool"),
                                execution_time=result.get("execution_time")
                            )
                            
                            combined_observations.append({
                                "tool": action.get("tool"),
                                "action": action,
                                "result": result
                            })
                            
                            if result.get("success"):
                                observations.append({
                                    "tool": action.get("tool"),
                                    "result": result.get("result")
                                })
                        
                        # æ›´æ–°å†å²ï¼ˆå¹¶è¡Œç»“æœåˆå¹¶ï¼‰
                        history.append({
                            "thought": step_result.get("thought"),
                            "actions": actions_to_execute,
                            "observations": combined_observations
                        })
                    
                    else:
                        # å•ä¸ªå·¥å…·æ‰§è¡Œï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                        action = actions_to_execute[0]
                        tool_name = action.get("tool")
                        method = action.get("method", "execute")
                        arguments = action.get("arguments", {})
                        
                        # è‡ªåŠ¨æ³¨å…¥ä¸Šä¸‹æ–‡å‚æ•°ï¼ˆå¦‚ memory_service çš„ session_idï¼‰
                        arguments = self._inject_context_params(tool_name, arguments)
                        
                        # å‘é€è¡ŒåŠ¨äº‹ä»¶
                        yield AgentEvent(
                            type=AgentEventType.ACTION,
                            data={
                                "tool": tool_name,
                                "method": method,
                                "arguments": arguments
                            },
                            iteration=iteration,
                            tool_name=tool_name
                        )
                        
                        # æ‰§è¡Œå·¥å…·ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
                        try:
                            execution_result = await asyncio.wait_for(
                                self.skill_executor.execute(
                                    skill_name=tool_name,
                                    method=method,
                                    arguments=arguments
                                ),
                                timeout=settings.AGENT_TOOL_TIMEOUT
                            )
                        except asyncio.TimeoutError:
                            logger.warning(f"Tool {tool_name} timeout after {settings.AGENT_TOOL_TIMEOUT}s")
                            execution_result = {
                                "success": False,
                                "error": f"å·¥å…· {tool_name} æ‰§è¡Œè¶…æ—¶ï¼ˆ{settings.AGENT_TOOL_TIMEOUT}ç§’ï¼‰",
                                "result": None,
                                "execution_time": settings.AGENT_TOOL_TIMEOUT
                            }
                        
                        # å‘é€è§‚å¯Ÿäº‹ä»¶
                        yield AgentEvent(
                            type=AgentEventType.OBSERVATION,
                            data=execution_result,
                            iteration=iteration,
                            tool_name=tool_name,
                            execution_time=execution_result.get("execution_time")
                        )
                        
                        # æ›´æ–°å†å²
                        history.append({
                            "thought": step_result.get("thought"),
                            "action": action,
                            "observation": execution_result
                        })
                        
                        # è®°å½•æˆåŠŸçš„è§‚å¯Ÿç»“æœ
                        if execution_result.get("success"):
                            observations.append({
                                "tool": tool_name,
                                "result": execution_result.get("result")
                            })
                        
                        # å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œå°è¯•é”™è¯¯æ¢å¤
                        if not execution_result.get("success"):
                            recovery_action = await self._handle_error(
                                task, action, execution_result.get("error", "Unknown error")
                            )
                            if recovery_action:
                                history[-1]["recovery"] = recovery_action
                

            except Exception as e:
                logger.error(f"ReAct iteration {iteration} failed: {e}")
                yield AgentEvent(
                    type=AgentEventType.ERROR,
                    data={"error": str(e), "iteration": iteration}
                )
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç”Ÿæˆæ€»ç»“ç­”æ¡ˆ
        logger.warning(f"Reached max iterations ({self.max_iterations})")
        
        final_answer = await self._generate_final_answer(task, observations)
        yield AgentEvent(
            type=AgentEventType.FINAL_ANSWER,
            data=final_answer,
            iteration=self.max_iterations,
            execution_time=time.time() - start_time
        )
        
        yield AgentEvent(
            type=AgentEventType.COMPLETE,
            data={
                "iterations": self.max_iterations,
                "total_time": time.time() - start_time,
                "tools_used": [obs["tool"] for obs in observations],
                "max_iterations_reached": True
            }
        )
    
    def _get_available_tools(
        self,
        enabled_tools: Optional[List[str]],
        disabled_tools: Optional[List[str]]
    ) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        all_tools = self.skill_executor.get_available_tools()
        
        if enabled_tools is not None:
            all_tools = [t for t in all_tools if t["name"] in enabled_tools]
        
        if disabled_tools:
            all_tools = [t for t in all_tools if t["name"] not in disabled_tools]
        
        return all_tools
    
    def _build_system_prompt(
        self,
        available_tools: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]]
    ) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        tools_text = format_tool_list(available_tools)
        context_text = self._format_context(context) if context else "æ— é¢å¤–ä¸Šä¸‹æ–‡"
        
        return AGENT_SYSTEM_PROMPT.format(
            available_tools=tools_text,
            context=context_text,
            current_date=datetime.now().strftime("%Y-%m-%d")
        )
    
    def _format_context(self, context: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        parts = []
        
        # ä¼šè¯ä¿¡æ¯
        if "session_id" in context:
            turn_count = context.get('turn_count', 0)
            message_count = context.get('message_count', 0)
            session_info = f"**å½“å‰ä¼šè¯**: session_id=`{context['session_id']}`, å·²æœ‰ {turn_count} è½®å¯¹è¯ï¼ˆå…± {message_count} æ¡æ¶ˆæ¯ï¼‰"
            if turn_count > 4:
                session_info += "\n> ğŸ’¡ å¦‚éœ€å›é¡¾å†å²å¯¹è¯ï¼Œè¯·ä½¿ç”¨ `memory_service.search()` æˆ– `memory_service.get_recent()`"
            parts.append(session_info)
        
        # ç®€çŸ­å¯¹è¯çš„æœ€è¿‘ä¸Šä¸‹æ–‡ï¼ˆè‡ªåŠ¨æ³¨å…¥ï¼‰
        if "recent_context" in context:
            parts.append(f"**æœ€è¿‘å¯¹è¯ï¼š**\n{context['recent_context']}")
        
        # å›¾ç‰‡åˆ†æç»“æœ
        if "image_analysis" in context:
            parts.append(f"**å›¾ç‰‡åˆ†æï¼š**\n{context['image_analysis']}")
        
        return "\n\n".join(parts) if parts else "æ–°ä¼šè¯ï¼Œæ— å†å²ä¸Šä¸‹æ–‡"
    
    async def _think(
        self,
        task: str,
        history: List[Dict[str, Any]],
        system_prompt: str
    ) -> Dict[str, Any]:
        """
        æ€è€ƒé˜¶æ®µï¼šè°ƒç”¨ LLM è¿›è¡Œæ¨ç†
        
        Returns:
            åŒ…å« thought å’Œ action/final_answer çš„å­—å…¸
        """
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": REACT_STEP_PROMPT.format(
                task=task,
                history=format_history(history)
            )}
        ]
        
        # è°ƒç”¨ LLMï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
        try:
            response = await asyncio.wait_for(
                self.llm_service.chat_completion(
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=settings.AGENT_DEFAULT_MAX_TOKENS
                ),
                timeout=settings.AGENT_LLM_CALL_TIMEOUT
            )
        except asyncio.TimeoutError:
            logger.warning(f"LLM call timeout after {settings.AGENT_LLM_CALL_TIMEOUT}s, continuing with timeout notice")
            # è¿”å›ä¸€ä¸ªè®©Agentæ„è¯†åˆ°è¶…æ—¶å¹¶ç»§ç»­çš„å“åº”ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            return {
                "thought": f"ä¸Šä¸€æ­¥LLMè°ƒç”¨è¶…æ—¶ï¼ˆ{settings.AGENT_LLM_CALL_TIMEOUT}ç§’ï¼‰ï¼Œéœ€è¦è°ƒæ•´ç­–ç•¥ç»§ç»­æ‰§è¡Œä»»åŠ¡ã€‚",
                "action": None  # æ²¡æœ‰actionï¼Œè®©ä¸‹ä¸€è½®è¿­ä»£é‡æ–°æ€è€ƒ
            }
        
        content = response.get("content", "")
        
        # è§£æ JSON å“åº”
        return self._parse_llm_response(content)
    
    def _parse_llm_response(self, content: str) -> Dict[str, Any]:
        """è§£æ LLM å“åº”ï¼Œæå– JSON"""
        # 1. å°è¯•æå– Markdown ä»£ç å—ä¸­çš„ JSON
        json_match = re.search(r"```json\s*(.*?)\s*```", content, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # 2. å°è¯•å¯»æ‰¾æœ€å¤–å±‚çš„ {}
            start = content.find("{")
            end = content.rfind("}")
            if start != -1 and end != -1:
                json_str = content[start:end+1]
            else:
                json_str = content.strip()
        
        try:
            # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é”™è¯¯ (å¦‚ newlines in strings)
            # ç®€å•æ›¿æ¢ï¼šå°†éè½¬ä¹‰çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸º \nï¼ˆè¿™å¾ˆå±é™©ï¼Œä»…ä½œä¸ºæœ€åå°è¯•ï¼‰
            # è¿™é‡Œå…ˆå°è¯•æ ‡å‡†è§£æ
            result = json.loads(json_str)
            return result
        except json.JSONDecodeError:
            pass

        # 3. å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå°è¯•ç”¨æ­£åˆ™æå–å…³é”®å­—æ®µ
        # è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨ LLM ç”Ÿæˆäº†ä¸åˆæ³•çš„ JSON (ä¾‹å¦‚å­—ç¬¦ä¸²é‡Œæœ‰æ¢è¡Œ)
        logger.warning(f"JSONDecodeError, attempting regex extraction. Content prefix: {content[:100]}")
        
        fallback_result = {}
        
        # æå– thought
        thought_match = re.search(r'"thought"\s*:\s*"(.*?)"', json_str, re.DOTALL)
        if thought_match:
            fallback_result["thought"] = thought_match.group(1)
            
        # æå– final_answer (æœ€é‡è¦)
        # å°è¯•åŒ¹é… "final_answer": "..." 
        # æ³¨æ„ï¼šè¿™æ— æ³•å¤„ç†åµŒå¥—å¼•å·ï¼Œä½†åœ¨ fallback åœºæ™¯ä¸‹æ¯”ç›´æ¥è¿”å› raw json å¥½
        final_answer_match = re.search(r'"final_answer"\s*:\s*"(.*)"\s*}?\s*$', json_str, re.DOTALL)
        if final_answer_match:
            fallback_result["final_answer"] = final_answer_match.group(1)
        
        if fallback_result:
            # å¦‚æœæå–åˆ°äº†ä»»ä½•ä¸œè¥¿ï¼Œå°±è¿”å›å®ƒ
            if "thought" not in fallback_result:
                fallback_result["thought"] = "ï¼ˆè§£ææ€è€ƒè¿‡ç¨‹æ—¶å‡ºé”™ï¼‰"
            return fallback_result

        # 4. å½»åº•å¤±è´¥ï¼Œåªèƒ½è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä½†åšä¸€äº›æ¸…ç†
        # å¦‚æœçœ‹èµ·æ¥åƒ JSON ä½†å¤±è´¥äº†ï¼Œå°è¯•ç›´æ¥æŠŠæ•´ä¸ª content å½“ä½œ final_answer å¯èƒ½ä¼šå¾ˆä¸‘
        # æˆ‘ä»¬å°è¯•ç§»é™¤ JSON çš„åŒ…è£…
        cleaned_content = content
        if start != -1 and end != -1:
             # å¦‚æœæ˜¯ "{ ... }" ç»“æ„ä½†è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯ key-value ç»“æ„
             pass

        logger.warning(f"Failed to parse LLM response as JSON: {content[:200]}")
        return {
            "thought": "JSON è§£æå¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹å“åº”",
            "final_answer": content  # å°†åŸå§‹å“åº”ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
        }
    
    def _is_duplicate_action(self, action: Dict[str, Any], history: List[Dict[str, Any]]) -> bool:
        """æ£€æŸ¥ action æ˜¯å¦åœ¨å†å²ä¸­é‡å¤å‡ºç°"""
        tool = action.get("tool")
        args = action.get("arguments", {})
        
        # ç®€å•åºåˆ—åŒ–å‚æ•°è¿›è¡Œæ¯”è¾ƒï¼Œé˜²æ­¢å­—å…¸é¡ºåºé—®é¢˜
        try:
            args_str = json.dumps(args, sort_keys=True)
        except:
            args_str = str(args)

        for step in history:
            prev_actions = []
            if "actions" in step:
                prev_actions.extend(step["actions"])
            elif "action" in step:
                prev_actions.append(step["action"])
            
            for prev_action in prev_actions:
                if prev_action.get("tool") == tool:
                    prev_args = prev_action.get("arguments", {})
                    try:
                        prev_args_str = json.dumps(prev_args, sort_keys=True)
                    except:
                        prev_args_str = str(prev_args)
                        
                    if prev_args_str == args_str:
                        return True
        return False

    async def _handle_error(
        self,
        task: str,
        failed_action: Dict[str, Any],
        error_message: str
    ) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†é”™è¯¯ï¼Œå°è¯•æ¢å¤
        
        Returns:
            æ¢å¤ç­–ç•¥æˆ– None
        """
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ Agentï¼Œéœ€è¦å¤„ç†å·¥å…·è°ƒç”¨é”™è¯¯ã€‚"},
            {"role": "user", "content": ERROR_RECOVERY_PROMPT.format(
                task=task,
                failed_action=json.dumps(failed_action, ensure_ascii=False),
                error_message=error_message
            )}
        ]
        
        try:
            response = await self.llm_service.chat_completion(
                messages=messages,
                temperature=0.3,  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„æ¢å¤ç­–ç•¥
                max_tokens=1024
            )
            
            content = response.get("content", "")
            return self._parse_llm_response(content)
            
        except Exception as e:
            logger.error(f"Error recovery failed: {e}")
            return None
    
    async def _generate_final_answer(
        self,
        task: str,
        observations: List[Dict[str, Any]]
    ) -> str:
        """
        åŸºäºæ”¶é›†çš„ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        """
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œéœ€è¦åŸºäºæ”¶é›†çš„ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚"},
            {"role": "user", "content": FINAL_ANSWER_TEMPLATE.format(
                task=task,
                observations=format_observations(observations)
            )}
        ]
        
        response = await self.llm_service.chat_completion(
            messages=messages,
            temperature=0.5,
            max_tokens=settings.AGENT_DEFAULT_MAX_TOKENS
        )
        
        return response.get("content", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ")


# å…¨å±€ ReAct å¼•æ“å®ä¾‹
react_engine = ReActEngine()
